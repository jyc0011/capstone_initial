{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import os\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "import imghdr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54743ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06957d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''사진속의 개의 얼굴을 박스로 찾아내고 해당 박스내에서 다시 개의 코의 부분만을 찾아내는 함수.'''\n",
    "def find_dog_nose(img_path, size=None, debug=False ):\n",
    "    img_name=img_path.strip(\"./dog_picture/.jpg\")\n",
    "    input_image = cv.imread(img_path)\n",
    "    input_image = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
    "    detector= dlib.cnn_face_detection_model_v1('./studydata/dogHeadDetector.dat')\n",
    "    predictor = dlib.shape_predictor('./studydata/landmarkDetector.dat')\n",
    "    image = input_image.copy() # 가져온 이미지를 복사하여 가져온 이미지 대신 복사 이미지를 수정\n",
    "    if size:\n",
    "        image = imutils.resize(image, width=size) # 만약 입력된 사이즈가 존재하면, 입력된 사이즈대로 영상 크기를 지정.\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) # 입력된 영상을 Gray(HxWx1(Intensity))형태로 변환\n",
    "    dets = detector(gray_image, 1) # 해당 이미지를 가져온 개 얼굴 인식 모델을 사용해서 개 얼굴 탐지 및 탐지된 얼굴 수를 입력.\n",
    "    print('Found {} faces.'.format(len(dets))) # 입력된 영상에서 찾은 개의 얼굴의 갯수를 표시\n",
    "    k = 0\n",
    "    \n",
    "    for (i, det) in enumerate(dets): # 감지된 얼굴 박스들의 수만큼 루프를 돌며 순서대로 박스 표시 \n",
    "        nosearea = input_image.copy() # 출력될 코 영역 사진\n",
    "        k=k+1\n",
    "        # 코의 SUBPLOT을 표시하기위한 인덱스 값\n",
    "        # 얼굴 영역의 얼굴 랜드마크를 결정한 다음 얼굴 랜드마크(x, y) 좌표를 NumPy Array로 변환합니다.\n",
    "        shape = predictor(image, det.rect) # 각 개의 얼굴의 부분()\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        print(shape)\n",
    "        # dlib의 사각형을 OpenCV bounding box로 변환(x, y, w, h)\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(det.rect) \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        # 감지된 얼굴 박스 위에 얼굴 #번호 텍스트를 입력\n",
    "        if debug:\n",
    "            # 얼굴 랜드마크에 포인트를 그립니다.\n",
    "            for (i, (x, y)) in enumerate(shape):# 해당 얼굴 박스에서 얼굴의 각 부분을 감지한 부분들의 수(총 6개)만큼 \n",
    "                                                 # 루프를 돌며 표시.\n",
    "                cv2.circle(image, (x, y), int(image.shape[1]/250), (0, 0, 255), -1)\n",
    "                # 각 랜드마크 지점(얼굴의 상위 3지점, 두 눈, 코 총 6개의 점)에 표시\n",
    "                if (i == 5): # 왼쪽 눈일때, 왼쪽 눈의 좌표값을 저장하고 해당 지점이 왼쪽 눈임을 텍스트로 표시\n",
    "                    eyel_x,eyel_y = x,y\n",
    "                    cv2.putText(image, \"Left eyes\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "                if (i == 2):# 오른쪽 눈일때, 오른쪽 눈의 좌표값을 저장하고 해당 지점이 오른쪽 눈임을 텍스트로 표시\n",
    "                    eyer_x,eyer_y = x,y\n",
    "                    cv2.putText(image, \"Right eyes\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "                if (i == 3):# 코의 중심 좌표값을 저장하고 해당 지점이 코의 중심임을 텍스트로 표시\n",
    "                    nose_x,nose_y = x,y\n",
    "                    cv2.putText(image, \"NoseDetect\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "                # cv2.putText(image, str(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (255, 255, 255), 1)\n",
    "        length_cut1=math.sqrt(abs(eyel_x - nose_x)**2+abs(eyel_y - nose_y)**2) \n",
    "        length_cut1= round(length_cut1) # 인덱스로 영역을 분할할 것이므로 반올림해준다.\n",
    "        length_cut2=math.sqrt(abs(eyer_x - nose_x)**2+abs(eyer_y - nose_y)**2)\n",
    "        length_cut2= round(length_cut2) # 인덱스로 영역을 분할할 것이므로 반올림해준다.\n",
    "        if (length_cut1 >length_cut2):\n",
    "            length_cut=round(length_cut1/3)\n",
    "            # 긴 쪽으로 하는데, 이것은 각도에 따라 눈과 코의 거리가 짧아져 코의 전반적인 부분이 짤릴수 있으므로.\n",
    "            # 먼저 왼쪽 눈과 코의 중심거리가 더 길다면 왼쪽 눈과 코의 중심거리를 CUT길이로 지정.\n",
    "        else:\n",
    "            length_cut=round(length_cut2/3)\n",
    "            # 만약 왼쪽 눈고 코의 중심거리가 오른쪽 눈과의 거리보다 짧다면 오른쪽 눈과의 거리를 CUT 길이로 지정\n",
    "        nosearea=nosearea[nose_y-length_cut:nose_y+length_cut,nose_x-length_cut:nose_x+length_cut]\n",
    "        # 코 영역 추출 [코의 중심에서 각 눈에서 코의 중심까지의 거리/2만큼 W,H를 지정]\n",
    "        \n",
    "        nosearea_nocolor=cv.cvtColor(nosearea, cv2.COLOR_BGR2GRAY)\n",
    "        # 코 영역을 BGR TO GRAY 컨버져\n",
    "        cv2.imwrite('./nosearea_dog{0}{1}.jpg'.format(k,img_name), nosearea_nocolor)\n",
    "        # 해당 코 영역을 GRAY채널로 JPG 저장\n",
    "        cv2.imwrite('./nosearea_dog{0}{1}_color.jpg'.format(k,img_name), nosearea)\n",
    "        # 해당 코 영역을 BGR채널로 JPG 저장\n",
    "        dst = cv.normalize(nosearea_nocolor, None, 0, 255, cv.NORM_MINMAX)\n",
    "        # 해당 GRAY 채널로 만든 코 영역을 스트레칭하여, 명암비를 확실히 함.\n",
    "        cv2.imwrite('./nosearea_dog{0}_{1}.jpg'.format(k,img_name), dst)\n",
    "        # 스트레칭한 GRAY채널 코 영역 JPG 저장\n",
    "        nosearea_color=cv.imread('./nosearea_dog{0}{1}_color.jpg'.format(k,img_name))\n",
    "        # BGR 채널로 저장한 코 영역 파일을 읽어옴\n",
    "        nosearea_nocolor=cv.imread('./nosearea_dog{0}{1}.jpg'.format(k,img_name))\n",
    "        # 저장한 GRAY채널 코 영역을 읽어옴\n",
    "        noseimg_st=cv.imread('./nosearea_dog{0}_{1}.jpg'.format(k,img_name))\n",
    "        # 저장한 스트레칭한 GRAY채널 코 영역을 읽어옴\n",
    "        \n",
    "        nosearea_color = cv.resize(nosearea_color, (1280, 720), interpolation=cv.INTER_LANCZOS4)\n",
    "        nosearea_nocolor = cv.resize(nosearea_nocolor, (1280, 720), interpolation=cv.INTER_LANCZOS4)\n",
    "        noseimg_st = cv.resize(noseimg_st, (1280, 720), interpolation=cv.INTER_LANCZOS4)\n",
    "        # 눈으로 보기 좋게 1280*720비율로 RESIZE, 보간은 가장 퀄리티가 좋은 64픽셀을 이용하는 Lanczos 보간법이용\n",
    "        \n",
    "        # 스트레칭한 이미지의 바이너리 이미지 생성\n",
    "        '''plt.subplot(1, len(dets), k) \n",
    "        plt.imshow(nosearea_color)\n",
    "        plt.title('NoseArea color')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()'''\n",
    "        plt.subplot(1, len(dets), k) \n",
    "        plt.imshow(nosearea_nocolor)\n",
    "        plt.title('NoseArea Not contrast stretching')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "        plt.imshow(noseimg_st)\n",
    "        plt.title('NoseArea contrast stretching')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    if (len(dets)>1):\n",
    "        print('we can only One your pet NosePrint. Check your background.\\n')\n",
    "    return './nosearea_dog{0}_{1}.jpg'.format(k,img_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
